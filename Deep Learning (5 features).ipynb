{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_df = pd.read_csv('./Clean_dataframe/clean_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LONGITUDE', 'ELEVATION','TMIN', 'TMAX' ,'PRCP','TAVG']\n",
    "X = Final_df[features]\n",
    "y = Final_df['sea_level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct network\n",
    "model = Sequential()\n",
    "\n",
    "# first layer\n",
    "model.add(Dense(32, input_shape=(6,), activation='relu'))\n",
    "\n",
    "# second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "139/139 [==============================] - 1s 2ms/step - loss: 7942597.5000 - val_loss: 7861225.5000\n",
      "Epoch 2/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 7493249.0000 - val_loss: 6956675.5000\n",
      "Epoch 3/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 6029301.5000 - val_loss: 4968781.5000\n",
      "Epoch 4/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 3886355.7500 - val_loss: 2916128.0000\n",
      "Epoch 5/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 2274165.2500 - val_loss: 1814074.6250\n",
      "Epoch 6/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 1529334.7500 - val_loss: 1342939.8750\n",
      "Epoch 7/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 1163916.8750 - val_loss: 1049986.5000\n",
      "Epoch 8/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 918434.8125 - val_loss: 842158.7500\n",
      "Epoch 9/10\n",
      "139/139 [==============================] - 0s 927us/step - loss: 750227.1875 - val_loss: 702041.8750\n",
      "Epoch 10/10\n",
      "139/139 [==============================] - 0s 1ms/step - loss: 639953.8125 - val_loss: 610055.9375\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_sc, y_train, validation_data=(X_test_sc, y_test), epochs=10, batch_size=512);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2163.4307],\n",
       "       [2762.0334],\n",
       "       [1680.4481],\n",
       "       ...,\n",
       "       [1131.8014],\n",
       "       [1909.7744],\n",
       "       [2792.4814]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 665us/step - loss: 610055.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "610055.9375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_sc, y_test, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_adv(hidden_neurons = 32, hidden_layers = 5, dropout = 0.5):\n",
    "    # build framework of model using for loop and if statement\n",
    "    model = Sequential()\n",
    "    \n",
    "    # adding number of layers = specified in calling of function\n",
    "    for layer in range(hidden_layers):\n",
    "        if layer == 0:\n",
    "            model.add(Dense(hidden_neurons, activation = 'relu', input_shape = (6,)))\n",
    "            model.add(Dropout(dropout))\n",
    "        else:\n",
    "            model.add(Dense(hidden_neurons, activation = 'relu'))\n",
    "            model.add(Dropout(dropout))\n",
    "    \n",
    "    # out put layer added here, Identity link function used as 'None'\n",
    "    model.add(Dense(1, activation = None))\n",
    "\n",
    "    # using mse as the metric to solve for \n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = KerasRegressor(build_fn = model_fn_adv, batch_size = 512, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params_deep = {\n",
    "    'hidden_neurons' : [20, 32, 64],\n",
    "    'hidden_layers'  : [2, 3, 5],\n",
    "    'dropout'        : [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'epochs'         : [10, 20, 30, 40, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(nn, param_grid = nn_params_deep, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fc47c236b20>,\n",
       "             param_grid={'dropout': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'epochs': [10, 20, 30, 40, 50],\n",
       "                         'hidden_layers': [2, 3, 5],\n",
       "                         'hidden_neurons': [20, 32, 64]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': 0.1, 'epochs': 10, 'hidden_layers': 5, 'hidden_neurons': 64}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-43316.03046875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions \n",
    "preds = gs.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9608463849025666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the R-squared\n",
    "metrics.r2_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LONGITUDE', 'ELEVATION','TMIN', 'TMAX' ,'PRCP','TAVG']\n",
    "X = Final_df[features]\n",
    "y = Final_df['sea_level'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = TimeseriesGenerator(X_train_sc, y_train, length=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = TimeseriesGenerator(X_test_sc, y_test, length=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_sequences[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(8, input_shape=input_shape, return_sequences=True)) # True if next layer is RNN\n",
    "model.add(GRU(8, return_sequences=False)) # False if next layer is Dense\n",
    "\n",
    "model.add(Dense(4, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(train_sequences, validation_data=test_sequences, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1110/1110 [==============================] - 6s 3ms/step - loss: 8084719.0000 - val_loss: 6919259.0000\n",
      "Epoch 2/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 7515687.0000 - val_loss: 6231496.0000\n",
      "Epoch 3/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 6641884.0000 - val_loss: 5338479.0000\n",
      "Epoch 4/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 5606938.0000 - val_loss: 4363603.0000\n",
      "Epoch 5/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 4522293.0000 - val_loss: 3402316.5000\n",
      "Epoch 6/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 3482965.5000 - val_loss: 2541319.2500\n",
      "Epoch 7/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 2571021.0000 - val_loss: 1850052.6250\n",
      "Epoch 8/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 1851107.8750 - val_loss: 1375370.1250\n",
      "Epoch 9/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 1362734.1250 - val_loss: 1130827.6250\n",
      "Epoch 10/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 1105670.8750 - val_loss: 1070892.8750\n",
      "Epoch 11/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 988626.8125 - val_loss: 933507.5625\n",
      "Epoch 12/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 811395.8750 - val_loss: 896805.5000\n",
      "Epoch 13/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 779966.6250 - val_loss: 803678.0625\n",
      "Epoch 14/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 747854.1875 - val_loss: 756742.1875\n",
      "Epoch 15/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 732730.1875 - val_loss: 746681.8750\n",
      "Epoch 16/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 689537.3750 - val_loss: 640843.3750\n",
      "Epoch 17/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 558577.6875 - val_loss: 369227.5000\n",
      "Epoch 18/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 422849.3438 - val_loss: 351683.4375\n",
      "Epoch 19/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 379370.9688 - val_loss: 257639.2812\n",
      "Epoch 20/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 349396.0938 - val_loss: 242060.6562\n",
      "Epoch 21/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 322459.1562 - val_loss: 273379.6562\n",
      "Epoch 22/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 309596.3438 - val_loss: 241319.4531\n",
      "Epoch 23/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 301013.0938 - val_loss: 238285.8750\n",
      "Epoch 24/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 296084.3125 - val_loss: 239554.0000\n",
      "Epoch 25/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 290995.0000 - val_loss: 219687.2031\n",
      "Epoch 26/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 288171.7188 - val_loss: 225415.3125\n",
      "Epoch 27/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 285988.0625 - val_loss: 226561.8125\n",
      "Epoch 28/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 283491.0000 - val_loss: 229822.2031\n",
      "Epoch 29/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 282593.5938 - val_loss: 233434.9844\n",
      "Epoch 30/100\n",
      "1110/1110 [==============================] - 3s 3ms/step - loss: 280941.7500 - val_loss: 231514.8906\n"
     ]
    }
   ],
   "source": [
    "# Add early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(GRU(8, input_shape=input_shape, return_sequences=True)) # True if next layer is RNN\n",
    "model2.add(GRU(8, return_sequences=False)) # False if next layer is Dense\n",
    "\n",
    "model2.add(Dense(4, activation='relu'))\n",
    "\n",
    "model2.add(Dense(1))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "es = EarlyStopping(patience = 5)\n",
    "\n",
    "history2 = model2.fit(train_sequences, validation_data=test_sequences, epochs=100, batch_size = 64, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
