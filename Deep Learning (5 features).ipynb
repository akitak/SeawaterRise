{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_df = pd.read_csv('./Clean_dataframe/clean_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LONGITUDE', 'ELEVATION','TMIN', 'TMAX' ,'PRCP','TAVG']\n",
    "X = Final_df[features]\n",
    "y = Final_df['sea_level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct network\n",
    "model = Sequential()\n",
    "\n",
    "# first layer\n",
    "model.add(Dense(32, input_shape=(6,), activation='relu'))\n",
    "\n",
    "# second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "139/139 [==============================] - 1s 2ms/step - loss: 7945449.5000 - mae: 2630.9585 - val_loss: 7882499.5000 - val_mae: 2617.6626\n",
      "Epoch 2/10\n",
      "139/139 [==============================] - 0s 859us/step - loss: 7596492.0000 - mae: 2566.2830 - val_loss: 7192419.0000 - val_mae: 2490.0212\n",
      "Epoch 3/10\n",
      "139/139 [==============================] - 0s 830us/step - loss: 6442424.5000 - mae: 2345.4912 - val_loss: 5568791.5000 - val_mae: 2166.2920\n",
      "Epoch 4/10\n",
      "139/139 [==============================] - 0s 823us/step - loss: 4539192.5000 - mae: 1932.9907 - val_loss: 3545583.0000 - val_mae: 1684.2080\n",
      "Epoch 5/10\n",
      "139/139 [==============================] - 0s 829us/step - loss: 2750986.5000 - mae: 1446.9980 - val_loss: 2128283.0000 - val_mae: 1235.9755\n",
      "Epoch 6/10\n",
      "139/139 [==============================] - 0s 832us/step - loss: 1751445.6250 - mae: 1082.2332 - val_loss: 1489847.6250 - val_mae: 965.1890\n",
      "Epoch 7/10\n",
      "139/139 [==============================] - 0s 839us/step - loss: 1301110.6250 - mae: 879.6146 - val_loss: 1164597.1250 - val_mae: 813.3401\n",
      "Epoch 8/10\n",
      "139/139 [==============================] - 0s 821us/step - loss: 1032567.8125 - mae: 750.8397 - val_loss: 940026.1875 - val_mae: 701.9556\n",
      "Epoch 9/10\n",
      "139/139 [==============================] - 0s 827us/step - loss: 844560.6250 - mae: 652.5150 - val_loss: 782736.3750 - val_mae: 615.2043\n",
      "Epoch 10/10\n",
      "139/139 [==============================] - 0s 799us/step - loss: 716065.8125 - mae: 580.8222 - val_loss: 676209.0625 - val_mae: 558.7137\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_sc, y_train, validation_data=(X_test_sc, y_test), epochs=10, batch_size=512);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2091.5767],\n",
       "       [2487.441 ],\n",
       "       [1629.4806],\n",
       "       ...,\n",
       "       [ 969.9026],\n",
       "       [1988.1176],\n",
       "       [2513.329 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 521us/step - loss: 676209.0625 - mae: 558.7137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[676209.0625, 558.7137451171875]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_sc, y_test, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_adv(hidden_neurons = 32, hidden_layers = 5, dropout = 0.5):\n",
    "    # build framework of model using for loop and if statement\n",
    "    model = Sequential()\n",
    "    \n",
    "    # adding number of layers = specified in calling of function\n",
    "    for layer in range(hidden_layers):\n",
    "        if layer == 0:\n",
    "            model.add(Dense(hidden_neurons, activation = 'relu', input_shape = (6,)))\n",
    "            model.add(Dropout(dropout))\n",
    "        else:\n",
    "            model.add(Dense(hidden_neurons, activation = 'relu'))\n",
    "            model.add(Dropout(dropout))\n",
    "    \n",
    "    # out put layer added here, Identity link function used as 'None'\n",
    "    model.add(Dense(1, activation = None))\n",
    "\n",
    "    # using mse as the metric to solve for \n",
    "    model.compile(loss = 'mse', optimizer = 'adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = KerasRegressor(build_fn = model_fn_adv, batch_size = 512, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params_deep = {\n",
    "    'hidden_neurons' : [20, 32, 64],\n",
    "    'hidden_layers'  : [2, 3, 5],\n",
    "    'dropout'        : [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'epochs'         : [10, 20, 30, 40, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(nn, param_grid = nn_params_deep, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fea87b10190>,\n",
       "             param_grid={'dropout': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'epochs': [10, 20, 30, 40, 50],\n",
       "                         'hidden_layers': [2, 3, 5],\n",
       "                         'hidden_neurons': [20, 32, 64]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout': 0.1, 'epochs': 10, 'hidden_layers': 5, 'hidden_neurons': 64}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-43213.00625"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions \n",
    "preds = gs.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9291870651738445"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the R-squared\n",
    "metrics.r2_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LONGITUDE', 'ELEVATION','TMIN', 'TMAX' ,'PRCP','TAVG']\n",
    "X = Final_df[features]\n",
    "y = Final_df['sea_level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = TimeseriesGenerator(X_train_sc, y_train, length=40, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = TimeseriesGenerator(X_test_sc, y_test, length=40, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_sequences[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(8, input_shape=input_shape, return_sequences=True)) # True if next layer is RNN\n",
    "model.add(GRU(8, return_sequences=False)) # False if next layer is Dense\n",
    "\n",
    "model.add(Dense(4, activation='relu'))\n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='bce', metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_sequences, validation_data=test_sequences, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Test loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='Train accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Test accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(GRU(8, input_shape=(3, 8), return_sequences=True)) # True if next layer is RNN\n",
    "model2.add(GRU(8, return_sequences=False)) # False if next layer is Dense\n",
    "\n",
    "model2.add(Dense(4, activation='relu'))\n",
    "\n",
    "model2.add(Dense(1))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='bce', metrics=['acc'])\n",
    "\n",
    "es = EarlyStopping(patience = 5)\n",
    "\n",
    "history2 = model2.fit(train_sequences, validation_data=test_sequences, epochs=100, batch_size = 64, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.history['loss'], label='Train loss')\n",
    "plt.plot(history2.history['val_loss'], label='Test loss')\n",
    "plt.plot(history.history['loss'], label='Original Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Original Test loss')\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
